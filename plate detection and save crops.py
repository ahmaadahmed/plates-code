# -*- coding: utf-8 -*-
"""egyptian_car_plates_recognition2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1poY_PCBymY8E9WDHVz7ugr1lXX-NWsQ9
"""

# pip install ArabicOcr

# Commented out IPython magic to ensure Python compatibility.
#clone YOLOv5 and
!git clone https://github.com/ultralytics/yolov5  # clone repo
# %cd yolov5
# %pip install -qr requirements.txt # install dependencies
# %pip install -q roboflow

import torch
import os
from IPython.display import Image, clear_output  # to display images

print(f"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})")

pip install easyocr

import cv2
import torch
# import easyocr

# import torch

model = torch.hub.load('.', 'custom', path='/content/best.pt', source='local')

images = '/content/images/'

for img in os.listdir(images):
    try:
        img_path = os.path.join(images, img)
        result = model(img_path)
        crops = result.crop(save=True)
    except (OSError, cv2.error) as e:
        print(f"Error processing image {img}: {e}")
        continue

# Image
images = '/content/images2/'
# Inference
for img in os.listdir(images):
    # check if the image ends with png
    result = model(images + img)
    crops = result.crop(save=True)

import os

directory = '/content/yolov5/runs/detect'

for filename in os.listdir(directory):
    for crops in os.listdir(os.path.join(directory, filename)):
        if crops == "crops":
            for plate in os.listdir(os.path.join(directory, filename, crops)):
                for img in os.listdir(os.path.join(directory, filename, crops, plate)):
                    img_path = os.path.join(directory, filename, crops, plate, img)
                    image = cv2.imread(img_path)
                    saved_img_path = '/content/saved_images'
                    # print(img)
                    cv2.imwrite('/content/saved_images' + "//" + img, image)

!zip -r "/content/saved_images/saved_imgs" "/content/saved_images"

from google.colab import files

files.download("/content/saved_images/saved_imgs.zip")

image = '/content/yolov5/runs/detect//exp496//crops//car-plate//1190.jpg'
image



import cv2

model = torch.hub.load('.', 'custom', path='/content/best.pt', source='local')
# Image
images = '/content/images/'
# Inference
for img in os.listdir(images):
    # check if the image ends with png
    results = model(images + img)
    results.show()

model = torch.hub.load('.', 'custom', path='/content/best.pt', source='local')
# Image
images = '/content/images3/'
# Inference
for img in os.listdir(images):
    # check if the image ends with png
    results = model(images + img)
    results.show()

model = torch.hub.load('.', 'custom', path='/content/best.pt', source='local')

def show_results(images):
  # Inference
  for img in os.listdir(images):
      img_path = images + img
      results = model(img_path)
      results.show()
  return

images = '/content/images/'
show_results(images)

def crop_img(img_path):
  result = model(img_path)
  crops = result.crop(save=True)
  return

img_path = '/content/images/14.jpg'
cropped_img = crop_img(img_path)

img = "/content/yolov5/runs/detect/exp/crops/car-plate/14.jpg"

# testim = mpimg.imread("/content/yolov5/runs/detect/exp8/crops/car-plate/14.jpg")
# imshow(testim)

def show_cropped_img(img_path):
    cropped_img = cv2.imread(img_path)
    cv2_imshow(cropped_img)

show_cropped_img("/content/yolov5/runs/detect/exp/crops/car-plate/14.jpg")

def resize_img(cropped_img, resized_img):
  cropped_img = cv2.imread(cropped_img)
  ratio = round(600/cropped_img.shape[1], 1)
  width = cropped_img.shape[1]*ratio
  width = round(width)
  height = cropped_img.shape[0]*ratio
  height = round(height)
  dim = (width, height)
  resized_img = cv2.resize(cropped_img, dim, interpolation = cv2.INTER_AREA)
  img = cv2_imshow(resized_img)
  cv2.imwrite(saved_img_path, resized_img)
  return

cropped_img = "/content/yolov5/runs/detect/exp/crops/car-plate/14.jpg"
saved_img_path = "/content/resized_images/14.jpg"
resize_img(cropped_img, saved_img_path)

pip install easyocr

pip install git+https://github.com/JaidedAI/EasyOCR.git

import easyocr

reader = easyocr.Reader(['ar','en'])

img = '/content/resized_images/14.jpg'

result = reader.readtext(img)

result

lst = []
for i in result:
  for z in i:
    if type(z) == str:
      lst.append(z)

lst[1]

#results = arabicocr.arabic_ocr(img,out_image="/content/out.jpg")

# for word in results:
#   print(word[1])

#results[1][1]

# lst = []
# for i in results[2][1]:
#   if i == " ":
#   lst.append(i)

# lst = []
# for i in results[2][1]:
#   if i == " ":
#     continue
#   else:
#     lst.append(i)

# lst

# for i in results[2][1]:
#   if i != " ":
#     print("".join(lst))